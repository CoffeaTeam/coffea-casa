# This is a GitHub workflow defining a set of jobs with a set of steps.
# ref: https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions
#
name: Test chart

# Trigger the workflow's on all PRs and pushes so that other contributors can
# run tests in their own forks. Avoid triggering these tests on changes to
# documentation only changes.
on:
  pull_request:
    paths-ignore:
      - "docs/**"
      - "**.md"
      - ".github/workflows/*"
      - "!.github/workflows/test-chart.yaml"
  push:
    paths-ignore:
      - "docs/**"
      - "**.md"
      - ".github/workflows/*"
      - "!.github/workflows/test-chart.yaml"
    branches-ignore:
      - "dependabot/**"
      - "pre-commit-ci-update-config"
      - "update-*"
      - "vuln-scan-*"
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-20.04
    timeout-minutes: 20

    strategy:
      # Keep running even if one variation of the job fail
      fail-fast: false
      matrix:
        # We run this job multiple times with different parameterization
        # specified below, these parameters have no meaning on their own and
        # gain meaning on how job steps use them.
        #
        # k3s-version: https://github.com/rancher/k3s/tags
        # k3s-channel: https://update.k3s.io/v1-release/channels
        #
        include:
          - k3s-channel: latest
            test: install
          - k3s-channel: stable
            test: install
          - k3s-channel: v1.21 # also test prePuller.hook
            test: install
            
    steps:
      - uses: actions/checkout@v3
        with:
          # chartpress requires git history to set chart version and image tags
          # correctly
          fetch-depth: 0

      # Starts a k8s cluster with NetworkPolicy enforcement and installs both
      # kubectl and helm
      #
      # ref: https://github.com/jupyterhub/action-k3s-helm/
      - uses: jupyterhub/action-k3s-helm@v3
        with:
          k3s-channel: ${{ matrix.k3s-channel }}
          metrics-enabled: false
          traefik-enabled: false
          docker-enabled: true

      - uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      # Install a local ACME server to fill the role of Let's Encrypt (LE). We
      # do this as the HTTP challenge sent out by an ACME server must be able to
      # reach the ACME client in our autohttps pod.
      - name: Install local ACME server
        run: |
          helm install pebble --repo https://jupyterhub.github.io/helm-chart/ pebble --values dev-config-pebble.yaml
      # Build our images if needed and update values.yaml with the tags
      - name: Install and run chartpress
        run: |
          pip3 install -r dev-requirements.txt
          chartpress
      # Generate values.schema.json from schema.yaml
      - name: Generate values.schema.json from schema.yaml
        run: |
          tools/generate-json-schema.py
      # Validate rendered helm templates against the k8s api-server with the
      # dedicated lint-and-validate-values.yaml config.
      - name: "Helm template --validate (with lint and validate config)"
        run: |
          helm template --validate jupyterhub ./jupyterhub --values tools/templates/lint-and-validate-values.yaml ${{ matrix.helm-template-validate-extra-args }}
      # It is only needed at this point forward as this is when we install
      # jupyterhub and the autohttps pod is about to start, so for CI
      # performance we delayed this until now and did other things in between.
      - name: Await local ACME server
        uses: jupyterhub/action-k8s-await-workloads@v1
        with:
          timeout: 150
          max-restarts: 1

      - name: "(Upgrade) Install PostgreSQL server chart"
        if: matrix.setup-postgresql-args
        run: |
          . ./ci/common
          helm install postgresql postgresql --repo=https://charts.bitnami.com/bitnami ${{ matrix.setup-postgresql-args }}
          await_kubectl_rollout statefulset/postgresql
      - name: "(Upgrade) Install ${{ matrix.upgrade-from }} chart"
        if: matrix.test == 'upgrade'
        run: |
          . ./ci/common
          if [ ${{ matrix.upgrade-from }} = stable -o ${{ matrix.upgrade-from }} = dev ]; then
            UPGRADE_FROM_VERSION=$(curl -sS https://jupyterhub.github.io/helm-chart/info.json | jq -er '.jupyterhub.${{ matrix.upgrade-from }}')
          else
            UPGRADE_FROM_VERSION=${{ matrix.upgrade-from }}
          fi
          echo "UPGRADE_FROM_VERSION=$UPGRADE_FROM_VERSION" >> $GITHUB_ENV
          echo ""
          echo "Installing already released jupyterhub version $UPGRADE_FROM_VERSION"
          # FIXME: We change the directory so jupyterhub the chart name won't be
          #        misunderstood as the local folder name.
          #
          #        https://github.com/helm/helm/issues/9244
          cd ci
          helm install jupyterhub --repo https://jupyterhub.github.io/helm-chart/ jupyterhub --values ../dev-config.yaml --version=$UPGRADE_FROM_VERSION ${{ matrix.upgrade-from-extra-args }}
      - name: "(Upgrade) Install helm diff"
        if: matrix.test == 'upgrade'
        run: |
          helm plugin install https://github.com/databus23/helm-diff
      - name: "(Upgrade) Helm diff ${{ matrix.upgrade-from }} chart with local chart"
        if: matrix.test == 'upgrade'
        run: |
          LOCAL_CHART_VERSION=$(cat jupyterhub/Chart.yaml | yq e '.version' -)
          export STRING_REPLACER_A=$LOCAL_CHART_VERSION
          export STRING_REPLACER_B=$UPGRADE_FROM_VERSION
          echo "NOTE: Helm diff upgrade won't trigger lookup functions, so it"
          echo "      will look like we seed new passwords all the time."
          echo
          echo "NOTE: For the helm diff only, we have replaced the new chart"
          echo "      version with the old chart version to reduce clutter."
          echo
          echo "      Old version: $UPGRADE_FROM_VERSION"
          echo "      New version: $LOCAL_CHART_VERSION (replaced)"
          echo
          helm diff upgrade --install jupyterhub ./jupyterhub --values dev-config.yaml \
              --values dev-config-local-chart-extra-config.yaml \
              ${{ matrix.local-chart-extra-args }} \
              --show-secrets \
              --context=3 \
              --post-renderer=ci/string-replacer.sh
      - name: "(Upgrade) Await ${{ matrix.upgrade-from }} chart"
        if: matrix.test == 'upgrade'
        uses: jupyterhub/action-k8s-await-workloads@v1
        with:
          timeout: 150
          max-restarts: 1

      - name: "(Upgrade) Await ${{ matrix.upgrade-from }} chart cert acquisition"
        if: matrix.test == 'upgrade'
        run: |
          . ./ci/common
          await_autohttps_tls_cert_acquisition
          await_autohttps_tls_cert_save
      - name: Create k8s test resources
        if: matrix.create-k8s-test-resources
        run: |
          kubectl apply -f ci/test-hub-existing-secret.yaml
      - name: "Install local chart"
        run: |
          helm upgrade --install jupyterhub ./jupyterhub \
              --values dev-config.yaml \
              --values dev-config-local-chart-extra-config.yaml \
              ${{ matrix.local-chart-extra-args }}
      - name: "Await local chart"
        uses: jupyterhub/action-k8s-await-workloads@v1
        with:
          timeout: 150
          max-restarts: 1

      - name: Await local chart cert acquisition
        run: |
          . ./ci/common
          await_autohttps_tls_cert_acquisition
      - name: Run tests
        continue-on-error: ${{ matrix.accept-failure == true }}
        run: |
          . ./ci/common
          # If you have problems with the tests add '--capture=no' to show stdout
          pytest --verbose --maxfail=2 --color=yes ./tests
      # ref: https://github.com/jupyterhub/action-k8s-namespace-report
      - name: Kubernetes namespace report
        uses: jupyterhub/action-k8s-namespace-report@v1
        if: always()
        with:
          important-workloads: deploy/hub deploy/proxy

      - name: Debug PostgreSQL logs on failure
        if: failure() && matrix.setup-postgresql-args
        run: |
          kubectl logs statefulset/postgresql
