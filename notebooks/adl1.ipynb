{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed.security import Security\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "from dask_jobqueue import HTCondorCluster\n",
    "from dask_jobqueue.htcondor import HTCondorJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    'Jets': { 'files': ['root://eospublic.cern.ch//eos/root-eos/benchmark/Run2012B_SingleMu.root'],\n",
    "             'treename': 'Events'\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program plots an event-level variable (in this case, MET, but switching it is as easy as a dict-key change). It also demonstrates an easy use of the book-keeping cutflow tool, to keep track of the number of events processed.\n",
    "# The processor class bundles our data analysis together while giving us some helpful tools.  It also leaves looping and chunks to the framework instead of us.\n",
    "class METProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        # Bins and categories for the histogram are defined here. For format, see https://coffeateam.github.io/coffea/stubs/coffea.hist.hist_tools.Hist.html && https://coffeateam.github.io/coffea/stubs/coffea.hist.hist_tools.Bin.html\n",
    "        self._columns = ['MET_pt']\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"\")\n",
    "        MET_axis = hist.Bin(\"MET\", \"MET [GeV]\", 50, 0, 100)\n",
    "        # The accumulator keeps our data chunks together for histogramming. It also gives us cutflow, which can be used to keep track of data.\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'MET': hist.Hist(\"Counts\", dataset_axis, MET_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int)\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._columns\n",
    "\n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "        # This is where we do our actual analysis. The df has dict keys equivalent to the TTree's.\n",
    "        dataset = df['dataset']\n",
    "        MET = df['MET_pt']\n",
    "        # We can define a new key for cutflow (in this case 'all events'). Then we can put values into it. We need += because it's per-chunk (demonstrated below)\n",
    "        output['cutflow']['all events'] += MET.size\n",
    "        output['cutflow']['number of chunks'] += 1\n",
    "        # This fills our histogram once our data is collected. Always use .flatten() to make sure the array is reduced. The output key will be as defined in __init__ for self._accumulator; the hist key ('MET=') will be defined in the bin.\n",
    "        output['MET'].fill(dataset=dataset, MET=MET.flatten())\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_dask = Security(tls_ca_file='/etc/cmsaf-secrets/ca.pem',\n",
    "               tls_worker_cert='/etc/cmsaf-secrets/usercert.pem',\n",
    "               tls_worker_key='/etc/cmsaf-secrets/usercert.pem',\n",
    "               tls_client_cert='/etc/cmsaf-secrets/usercert.pem',\n",
    "               tls_client_key='/etc/cmsaf-secrets/usercert.pem',\n",
    "               tls_scheduler_cert='/etc/cmsaf-secrets/hostcert.pem',\n",
    "               tls_scheduler_key='/etc/cmsaf-secrets/hostcert.pem',\n",
    "               require_encryption=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTCondorJob.submit_command = \"condor_submit -spool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "cluster = HTCondorCluster(cores=4,\n",
    "                          memory=\"2GB\",\n",
    "                          disk=\"1GB\",\n",
    "                          log_directory=\"logs\",\n",
    "                          silence_logs=\"debug\",\n",
    "                          scheduler_options= {\"dashboard_address\":\"8786\",\"port\":8787, \"external_address\": \"129.93.183.33:8787\"},\n",
    "                          # HTCondor submit script\n",
    "                          job_extra={\"universe\": \"docker\",\n",
    "                                     # To be used with coffea-casa:0.1.11\n",
    "                                     \"encrypt_input_files\": \"/etc/cmsaf-secrets/xcache_token\",\n",
    "                                     #\"docker_network_type\": \"host\",\n",
    "                                     \"docker_image\": \"oshadura/coffea-casa-analysis:0.1.11\", \n",
    "                                     \"container_service_names\": \"dask\",\n",
    "                                     \"dask_container_port\": \"8787\",\n",
    "                                     \"should_transfer_files\": \"YES\",\n",
    "                                     \"when_to_transfer_output\": \"ON_EXIT\",\n",
    "                                     \"+DaskSchedulerAddress\": '\"129.93.183.33:8787\"',\n",
    "                                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)#, security=sec_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cachestrategy = 'dask-worker'\n",
    "exe_args = {\n",
    "        'client': client,\n",
    "        #'cachestrategy': cachestrategy,\n",
    "        #'savemetrics': True,\n",
    "        #'worker_affinity': True if cachestrategy is not None else False,\n",
    "    }\n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                treename = 'Events',\n",
    "                                processor_instance = METProcessor(),\n",
    "                                executor = processor.dask_executor,\n",
    "                                executor_args = exe_args\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a 1D histogram from the data output to the 'MET' key. fill_opts are optional, to fill the graph (default is a line).\n",
    "hist.plot1d(output['MET'], overlay='dataset', fill_opts={'edgecolor': (0,0,0,0.3), 'alpha': 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy way to print all cutflow dict values. Can just do print(output['cutflow'][\"KEY_NAME\"]) for one.\n",
    "for key, value in output['cutflow'].items():\n",
    "    print(key, value)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
